{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efc2727e308855d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# ðŸš€ Next 5 Minutes\n",
    "\n",
    "Now you've learned the basics -- now we demonstrate why Trace can be the fundamental basic block to build increasingly complex agent systems.\n",
    "\n",
    "Trace supports building agents can rewrite its own rules, logic, and behaviors. Self-modification is the key design idea of Trace. Trace agents self-evolve by embedding the philosophy of *trial-and-error* (the Reinforcement Learning way!). A Trace agent first proposes a solution, tries this solution out, receives feedback, and then improve. This propose-feedback-improve loop is at the heart of policy gradient algorithms (such as [PPO](https://arxiv.org/abs/1707.06347), which is used in RLHF -- Reinforcement Learning from Human Feedback). The ability to modify its own behavior is the core of an intelligent system.\n",
    "\n",
    "Although LLMs can generate code, actions, or anything a human can, controlling what they generate is not as easy. Trace takes the programmer's approach -- an intelligent system is made of a series of coding blocks, some of which might make an LLM call, but others might access a database, or scrap a web page. Human engineers are great at writing these kinds of systems. In order for these systems to be \"intelligent\" -- human engineers need to add many corner cases to be \"reactive\" to different inputs.\n",
    "\n",
    "Trace uses decorators like `@bundle` or `@model` and data wrappers like `node` to expose different parts of these programs to an LLM. An LLM can rewrite the entire or only parts of system based on the user's specification. An LLM can change various parts of this system, with feedback they receive from the environment. Trace allows users to exert control over the LLM code-generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d7b470a57d80a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import autogen\n",
    "from opto.trace import node, bundle\n",
    "from opto.optimizers import OptoPrime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa000905-9028-4f6b-b42a-5a421ebf31c6",
   "metadata": {},
   "source": [
    "A simple example of how Trace allows the user to design an agent, and how the agent self-modifies its own behavior to adapt to the environment, we can take a look at the classic game of Battleship.\n",
    "\n",
    "```{image} ../images/dall_e_battleship.jpeg\n",
    ":alt: battleship\n",
    ":class: bg-primary mb-1\n",
    ":align: center\n",
    "```\n",
    "\n",
    "(Image credit: DALL-E by OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028904a8-9e06-4886-9e1a-3dd74b9d69ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79803b5-12b5-413f-8e5f-5df10224c0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd20aa4-422b-42af-be2a-a4494e2957db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd33de-aa4b-4183-963e-6f18618e81d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d98d8c37-9aca-4eb3-b098-e2fee002632d",
   "metadata": {},
   "source": [
    "Let's look at another coding problem (adapted from [LeetCode](https://leetcode.com/)):\n",
    "\n",
    "**Problem**: Given an input of a Python list of list, which represents a map, where `1` represents land and `0` represents water, can we count how many unique islands are on this map?\n",
    "\n",
    "```\n",
    "Input: island = [\n",
    "  [\"1\",\"1\",\"1\",\"1\",\"0\"],\n",
    "  [\"1\",\"1\",\"0\",\"1\",\"0\"],\n",
    "  [\"1\",\"1\",\"0\",\"0\",\"0\"],\n",
    "  [\"0\",\"0\",\"0\",\"0\",\"0\"]\n",
    "]\n",
    "Output: 1\n",
    "Example 2:\n",
    "\n",
    "Input: island = [\n",
    "  [\"1\",\"1\",\"0\",\"0\",\"0\"],\n",
    "  [\"1\",\"1\",\"0\",\"0\",\"0\"],\n",
    "  [\"0\",\"0\",\"1\",\"0\",\"0\"],\n",
    "  [\"0\",\"0\",\"0\",\"1\",\"1\"]\n",
    "]\n",
    "Output: 3\n",
    "```\n",
    "\n",
    "Oftentimes, these problems come with unit tests. However, these unit tests are not exhaustive and there can be hidden tests as well. In fact, can we write a self-evolving system to help improve a code-generation agent's behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbee382-e363-456f-84c7-9f00ad1b53ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0233ca6c-153d-4253-b77f-c4c5e8747cc7",
   "metadata": {},
   "source": [
    "Want to see more:\n",
    "\n",
    "Battleship\n",
    "\n",
    "Multi-Agent Negotiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d293d-2453-493a-8fa0-83a42835d145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verbal-gym",
   "language": "python",
   "name": "verbal-gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
