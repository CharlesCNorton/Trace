<html lang="en"><head>
<title>Trace</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="title" content="Trace">

<!-- Fontawesome -->
<link type="text/css" href="vendor/@fortawesome/fontawesome-free/css/all.min.css" rel="stylesheet">

<!-- Prism -->
<link type="text/css" href="vendor/prismjs/themes/prism.css" rel="stylesheet">

<!-- VectorMap -->
<link rel="stylesheet" href="vendor/jqvmap/dist/jqvmap.min.css">

<!-- Rocket CSS -->
<link type="text/css" href="css/rocket.css" rel="stylesheet">

<!-- NOTICE: You can use the _analytics.html partial to include production code specific code & trackers -->
<style>
.bg-primary {
  background-color: #2E72EF !important;
}
.pattern {
    background-image: url(assets/img/patterns/wave.svg);
}
.bg-primary .nav-link {
    color: white;
}

.bg-primary .tab-content .nav-link {
    color: #4A5073;
}

.wrap-code {
    white-space: pre-wrap !important;
    word-break: normal;
    word-wrap: break-word !important;
}

pre[class*="language-"],
code[class*="language-"] {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    font-size: 0.9em;
    overflow: auto;

}

</style>

</head>

<body>
  <header class="header-global">
  <nav id="navbar-main" class="navbar navbar-main navbar-expand-lg navbar-dark navbar-theme-primary headroom py-lg-2 px-lg-6 headroom--not-bottom headroom--pinned headroom--top">
      <div class="container">
          <div class="navbar-collapse collapse" id="navbar_global">
              <div class="navbar-collapse-header">
                  <div class="row">
                      <div class="col-6 collapse-brand">
                          <a class="d-flex align-items-center" href="index.html">
                              <!-- <img src="assets/img/brand/dark.svg" alt="Logo dark"> -->
                          </a>
                      </div>
                      <div class="col-6 collapse-close">
                          <a href="#navbar_global" class="fas fa-times" data-toggle="collapse" data-target="#navbar_global" aria-controls="navbar_global" aria-expanded="false" aria-label="Toggle navigation"></a>
                      </div>
                  </div>
              </div>
              <ul class="navbar-nav navbar-nav-hover justify-content-center">
                  <li class="nav-item">
                      <a href="index.html" class="nav-link">Overview</a>
                  </li>
              </ul>
          </div>
          <div class="d-none d-lg-block">
             <!-- <a href="#" target="_blank" class="btn btn-secondary btn-pricing-plan animate-up-2 mr-3"><i class="fab fa-github mr-2"></i> Repo (Coming soon)</a> -->
             <a href="https://microsoft.github.io/Trace/assets/file/trace.pdf" target="_blank" class="btn btn-outline-white animate-up-2 mr-3"><i class="fas fa-paperclip mr-2"></i>Paper</a>
             <a href="#" target="_blank" class="btn btn-outline-white animate-up-2 mr-3"><i class="fab fa-github mr-2"></i>Code (In 1 month)</a>
             <!-- <a href="#" target="_blank" class="btn btn-outline-white btn-docs animate-up-2"><i class="fas fa-book mr-2"></i> Docs (Coming soon)</a> -->
          </div>
          <div class="d-flex d-lg-none align-items-center ml-auto">
              <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar_global" aria-controls="navbar_global" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
          </div>
      </div>
  </nav>
</header>
  <main>

      <!-- <div class="preloader bg-soft flex-column justify-content-center align-items-center">
  <img class="loader-element" src="assets/img/brand/dark.svg" height="50" alt="Rocket logo">
      </div> -->
<!-- Building End-to-end Automatic Optimization of AI Systems <br> -->
      <!-- Hero -->
      <section class="section-header pb-11 pb-lg-13 bg-primary text-white">
          <div class="container">
              <div class="row justify-content-center">
                  <div class="col-12 col-md-10 text-center">
                      <h1 class="display-1 mb-4">Trace, the new Auto-Diff</h1>
                      <!-- Building End-to-end Automatic Optimization of AI Systems <br>  -->
                      <p class="lead mb-5 px-lg-5">The Path to Self-Adapting AI Agents </p>
                  </div>
              </div>
              <div class="row justify-content-center">
                  <div class="col-12 col-md-7">
                      <form action="https://gmail.us14.list-manage.com/subscribe/post?u=3941794c6b4e6156e45807fd7&amp;id=60c13fc4cd&amp;f_id=00d5c2e1f0"
                        method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" target="_self" novalidate="" class="form-group mb-4">
                          <div class="d-flex flex-row justify-content-center">
                              <div class="input-group">
                                  <input class="form-control form-control-xl border-light" placeholder="name@example.com" type="email" name="EMAIL" required="">
                                  <div aria-hidden="true" style="position: absolute; left: -5000px;"><input type="text" name="b_3941794c6b4e6156e45807fd7_60c13fc4cd" tabindex="-1" value=""></div> <div class="input-group-prepend">
                                    <button type="submit" class="btn btn-secondary btn-sm rounded-right">Sign Up for Release</button>
                                  </div>
                              </div>
                          </div>
                      </form>
                  </div>
              </div>
          </div>
          <div class="pattern bottom"></div>
      </section>
      <div class="section pt-0">
          <div class="container mt-n9 mt-lg-n12 z-2">
              <div class="row justify-content-center">
                  <div class="col-12 col-md-10">
                      <div class="position-relative">
                          <!-- <button type="button" class="hotspot-popover bg-white" style="top: 35%; left: 5%;" data-container="body" data-toggle="popover" title="Menu" data-content="Use this menu to find the majority of a platform's essential functions."></button> -->
                          <button type="button" class="hotspot-popover bg-primary" style="top: 55%; left: 35%;" data-container="body" data-toggle="popover" title="" data-content="After two optimizer iterations, the code becomes an enumeration strategy that a novice programmer might write." data-original-title="Learned to Enumerate"></button>
                          <button type="button" class="hotspot-popover bg-primary" style="top: 10%; left: 80%;" data-container="body" data-toggle="popover" title="" data-content="In later iterations, the code is automatically optimized to an explore-exploit strategy like what a sophisticated programmer might write." data-original-title="Learned to Balance Exploration with Exploitation"></button>
                          <!-- <img class="shadow-box rounded" src="assets/img/saas-platform.png" alt="SaaS preview"> -->
                          <img class="shadow-box rounded" src="images/main_figure.png" alt="SaaS preview">
                      </div>
                  </div>
              </div>
          </div>
      </div>

    <section class="section section-lg pt-0 pb-0">
        <div class="container justify-content-center mb-5">
            <div class="row justify-content-center mb-5">
                <div class="col-12 col-md-8 text-center">
                    <h2 class="h1 font-weight-bolder mb-4">What is Trace?</h2>
                    <p>Trace is a new AutoDiff-like tool for training AI systems end-to-end with general feedback (like numerical losses, natural language, errors, etc.).  This gradient-free generalization of back-propagation is made possible by a new mathematical formulation of optimization, we call Optimization with Trace Oracle (OPTO).  Trace is implemented as a PyTorch-like Python library. With Trace, users can easily create trainable AI systems and train them like training neural networks!
                        <!-- Instead of propagating gradients (which are not necessarily defined for AI systems),
                        Trace propagates <i>Minimal Subgraphs</i> (Trace Graphs), which can be used to recover propagated when applicable. Trace is implemented as a PyTorch-like Python library with which users can easily create trainable AI systems and train them like training neural networks. </p> -->
                </div>
            </div>
            <div class="row">
                <div class="col-12 col-lg-4 mb-4 mb-lg-0">
                    <div class="card bg-white border-light shadow-soft p-4">
                        <div class="card-body p-3 text-center">
                            <div class="icon icon-lg icon-primary justify-content-start mb-3">
                                <span class="fas fa-cogs"></span>
                            </div>
                            <!-- <h4 class="mb-4">Chained End-to-End Optimization</h4> -->
                            <!-- <h4 class="mb-4">End-to-end Optimization</h4>
                            <p> An AI system has many modules. Some modules are pure Python programs. Some make calls to other APIs to retrieve or generate contents.
                                Trace allows you to specify tunable parts of your system and optimize your entire workflow end-to-end using feedback (like scores, natural language, errors, etc.).
                            </p> -->
                            <h4 class="mb-4">End-to-End Optimization via LLM</h4>
                            <!-- <p>Trace is a new AutoDiff-like tool for training AI systems. This generalization is made possible by a new mathematical formulation of optimization, we call Optimization with Trace Oracle (OPTO), which can describe end-to-end optimization of AI systems with general feedback (such as numerical losses, natural language, errors, or images).</p> -->
                            <p>An AI system has many modules. Some modules are pure Python programs. Some make calls to other APIs to retrieve or generate contents. Trace allows you to specify tunable parts of your system and optimize the entire system with general feedback using LLM-based optimizers.</p>
                        </div>
                    </div>
                </div>
                <div class="col-12 col-lg-4 mb-4 mb-lg-0">
                    <div class="card bg-white border-light shadow-soft p-4">
                        <div class="card-body p-3 text-center">
                            <div class="icon icon-lg icon-primary justify-content-start mb-3">
                                <span class="fab fa-python"></span>
                            </div>
                            <h4 class="mb-4 py-lg-1">Native Python Support</h4>
                            <p>Trace gives users full flexibility in building self-learning AI systems. It provides two primitives <button type="button" class="btn btn-secondary btn-sm pb-0 pt-0" data-container="body" data-toggle="popover" data-placement="top" title="node" data-content="node can be used to wrap over normal Python objects like a string, number, list, or dictionary.">node</button>
                                <button type="button" class="btn btn-secondary btn-sm pb-0 pt-0" data-container="body" data-toggle="popover" data-placement="bottom" title="bundle" data-content="bundle is a decorator to wrap over Python functions.">bundle</button>  to wrap over Python objects and functions. This design makes Trace compatible with any Python program, handle the dynamic nature of AI systems, and
                                 capable of optimizing a mixture of <u>code</u>,
                                <u>string</u>, <u>numbers</u>, and <u>objects</u>, etc.
                            </p>
                        </div>
                    </div>
                </div>
                <div class="col-12 col-lg-4">
                    <div class="card bg-white border-light shadow-soft p-4">
                        <div class="card-body p-3 text-center">
                            <div class="icon icon-lg icon-primary justify-content-start mb-3">
                                <span class="fas fa-project-diagram"></span>
                            </div>
                            <h4 class="mb-4">Platform for Developing New Algorithms </h4>
                            <p>Instead of propagating gradients, Trace propagates <i>Minimal Subgraphs</i> which maximally preserve information of the computation process. This generalization creates an abstraction of problem domains and allows users to develop new optimization algorithms that can be applied to diverse AI systems.
                                 <!-- </p>
                            <h4 class="mb-4">Trace Graph</h4>
                            <p>Instead of propagating gradients, Trace propagates <i>Minimal Subgraphs</i>, which can be used to recover propagated when applicable.
                            The graph can be flexibly defined with generic Python functions and operations and can be used by other libraries to develop new optimization algorithms.</p> -->
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section section-lg pt-9 pb-5 bg-primary">
        <div class="pattern top"></div>
        <div class="container justify-content-center mb-5">
            <div class="row">
                <div class="col-lg-3">
                    <!-- Tab Nav -->
                    <ul class="nav nav-pills square nav-fill flex-column vertical-tab" id="tab12" role="tablist">
                        <li class="nav-item">
                            <a class="nav-link active" id="home-tab-3" data-toggle="tab" href="#tab-14" role="tab" aria-controls="tab-14" aria-selected="true"><span class="d-block"><i class="fab fa-python mr-2"></i>Native Python Support</span></a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" id="profile-tab-3" data-toggle="tab" href="#tab-15" role="tab" aria-controls="tab-15" aria-selected="false"><span class="d-block"><i class="fas fa-cogs mr-2"></i>End-to-End Optimization</span></a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" id="contact-tab-3" data-toggle="tab" href="#tab-16" role="tab" aria-controls="tab-16" aria-selected="false"><span class="d-block"><i class="far fa-sun mr-2"></i>Trace Graph</span></a>
                        </li>
                    </ul>
                    <!-- End of Tab Nav -->
                </div>
                <div class="col-lg-9">
                    <!-- Tab Content -->
                    <div class="card">
                        <div class="card-body p-5">
                            <div class="tab-content" id="tabcontent">
                                <div class="tab-pane fade show active" id="tab-14" role="tabpanel" aria-labelledby="tab-14">
                                    <p>Trace is built to flexibly support Python programs written by a user. 
                                       Consider building an AI agent for the classic Battleship game. In Battleship, a player's goal to hit the ships on a hidden board as fast as possible. To this end, the player must devise strategies to cleverly locate the ships and attack them, instead of slowly enumerating the board.  
                                    To build an AI agent with Trace, one simply needs to program the workflow of the agent and declare the parameters, just like programming a neural network architecture. </p>
                                    <p>In this example, we will design an agent with two components: a reason function and an act function. To do this, we provide just a basic description of what these two functions should do (reason should analyze the board and act should select a target coordinate). Then we leave the content to be blank and just set those two functions to be trainable (by setting <code>trainable=True</code>). We highlight that, at this point, the agent doesn't know how the Battleship API works. It must not only learn how to play the game, but also learn how to use the unknown API. </p>
                                    <!-- Training result -->
                                    <div class="row justify-content-center pt-2 pb-2">
                                        <div class="col-12">
                                            <!-- Tab Nav -->
                                            <div class="nav-wrapper position-relative mb-2">
                                                <ul class="nav nav-pills nav-fill flex-column flex-md-row" id="tabs-icons-text" role="tablist">
                                                    <li class="nav-item">
                                                        <a class="nav-link mb-sm-3 mb-md-0 active" id="tabs-icons-text-1-tab" data-toggle="tab" href="#tabs-icons-text-1" role="tab" aria-controls="tabs-icons-text-1" aria-selected="true"><i class="fas fa-robot mr-2"></i>Agent Code</a>
                                                    </li>
                                                    <li class="nav-item">
                                                        <a class="nav-link mb-sm-3 mb-md-0" id="tabs-icons-text-2-tab" data-toggle="tab" href="#tabs-icons-text-2" role="tab" aria-controls="tabs-icons-text-2" aria-selected="false"><i class="fas fa-laptop-code mr-2"></i>Optimize</a>
                                                    </li>
                                                </ul>
                                            </div>
                                            <!-- End of Tab Nav -->
                                            <!-- Tab Content -->
                                            <div class="card">
                                                <div class="card-body p-0">
                                                    <div class="tab-content" id="tabcontent2">
                                                        <div class="tab-pane fade show active" id="tabs-icons-text-1" role="tabpanel" aria-labelledby="tabs-icons-text-1-tab">
                                                            <pre><code class="language-python">
    from trace import bundle, trace_class

    @trace_class
    class Agent:

        def __call__(self, map):
            return self.select_coordinate(map).data

        def select_coordinate(self, map):
            plan = self.reason(map)
            output = self.act(map, plan)
            return output

        @bundle(trainable=True)
        def act(self, map, plan):
            """
            Given a map, select a target coordinate in a game.
            X denotes hits, O denotes misses, and . denotes unknown positions.
            """
            return

        @bundle(trainable=True)
        def reason(self, map):
            """
            Given a map, analyze the board in a game.
            X denotes hits, O denotes misses, and . denotes unknown positions.
            """
            return
                                                            </code></pre>
                                                        </div>
                                                        <div class="tab-pane fade" id="tabs-icons-text-2" role="tabpanel" aria-labelledby="tabs-icons-text-2-tab">
                                                            <pre><code class="language-python">
    from trace import node, trace_class, GRAPH

    board = Battleship()
    obs = node(board.get_shots())  # init observation
    i, max_calls = 0, 10
    while i < max_calls:
        GRAPH.clear()
        try:
            output = policy.select_coordinate(obs)
            obs, reward, terminal, feedback = board.placing_shot(output.data)
        except TraceExecutionError as e:
            output = e.exception_node
            feedback = output.data
            reward, terminal = 0, False

        if terminal:
            break

        # Update
        optimizer.zero_feedback()
        optimizer.backward(output, feedback)
        optimizer.step(verbose=True)
                                                            </code></pre>
                                                        </div>
                                                    </div>
                                                </div>
                                            </div>
                                            <!-- End of Tab Content -->
                                            
                                        </div>
                                    </div>

                                </div>
                                <div class="tab-pane fade" id="tab-15" role="tabpanel" aria-labelledby="tab-15">
                                    <p>Trace can allow the optimization of heterogenous data types. Primitive Python objects are wrapped in <button type="button" class="btn btn-secondary btn-sm pb-0 pt-0" data-container="body" data-toggle="popover" data-placement="top" title="node" data-content="node can be used to wrap over normal Python objects like a string, number, list, or dictionary.">node</button>.
                                    We can allow our optimizer to update these objects based on task feedback.
                                    </p>
                                    <pre>
                                        <code class="language-python">
    from trace import node
    w = node(3)
    x = node({"learning_rate": 1e-3})
    y = node("You are a helpful assistant.")
    z = node([2, 5, 3])</code>
                                </pre>
                                <br>
                                <p>Similarly, <button type="button" class="btn btn-secondary btn-sm pb-0 pt-0" data-container="body" data-toggle="popover" data-placement="bottom" title="bundle" data-content="bundle is a decorator to wrap over Python functions.">bundle</button> allows us to represent Python functions as a node. We can describe what the function is doing, or allowing the optimizer to change the content of this function.</p>
                                <pre>
                                    <code class="language-python">
    import math
    from trace import bundle

    @bundle(trainable=True)
    def sigmoid(x):
        return 1 / (1 + math.exp(-x))</code>
                                </pre>
                                <br>
                                <p>The most impressive part of Trace is the immense <u>flexibility</u>. We can write a Python program and ask a generic LLM-based optimizer to update many different parts of this program.
                                Note in the example below, the optimizer updates the prompt template and two functions at the same time.
                                </p>
                                <pre>
                                    <code class="language-python">
    from trace import node, trace_class

    @trace_class
    class Predict(LLMCallable):
        def __init__(self):
            super().__init__()

            self.demos = []
            self.prompt_template = dedent("""
            Given the fields `question`, produce the fields `answer`.
            ---
            Follow the following format.

            Question:
            Answer:
            ---
            Question: {}
            Answer:""")
            self.prompt_template = node(self.prompt_template, trainable=True)

        @bundle(trainable=True)
        def extract_answer(self, prompt_template, question, response):
            """
            Need to read in the response, which can contain additional thought, delibration and an answer.
            Use code to process the response and find where the answer is.
            Can use self.call_llm("Return the answer from this text: " + response) again to refine the answer if necessary.

            Args:
                prompt_template: The prompt that was used to query LLM to get the response
                question: Question has a text describing the question but also "Options"
                response: LLM returned a string response
            """
            answer = response.split("Answer:")[1].strip()
            return answer

        @bundle(trainable=True)
        def create_prompt(self, prompt_template, question):
            """
            The function takes in a question and then add to the prompt for LLM to answer.
            Args:
                prompt_template: some guidance/hints/suggestions for LLM
                question: the question for the LLM to answer
            """
            return prompt_template.format(question)

        def forward(self, question):
            """
            question: text

            We read in a question and produces a response
            """
            user_prompt = self.create_prompt(self.prompt_template, question)
            response = self.call_llm(user_prompt)
            answer = self.extract_answer(self.prompt_template, question, response)
            return answer
                                    </code>
                                </pre>
                                </div>
                                <div class="tab-pane fade" id="tab-16" role="tabpanel" aria-labelledby="tab-16">
                                    <p>Trace implicitly constructs a computation graph through Python operators and functions. The graph 
                                        represents the actual execution of the user-defined workflow (not the same as the original program).
                                        The original program can have complicated logic, but the actual execution graph (<i>Minimal Subgraph</i>) contains
                                        the necessary information for an LLM-based optimizer to change the workflow. For an example program:
                                    </p>
                                    <pre>
                                        <code class="language-python">
    from trace import node

    x = node(-1.0, trainable=True)
    a = bar(x) # automatically traced
    b = unknown_func()  # not traced
    y = a + b
    z = a * y
    z.backward(feedback="Output should be larger.", visualize=True)</code>
                                    </pre>
                                    <p>If we visualize during the backward pass, we obtained a partial graph of how the program is run. Trace
                                        allows user to <u><b>design</b></u> which part of the workflow they want to present to the LLM optimizer.
                                        Users can choose to present as much information (i.e., a complete picture of the workflow) or 
                                        as little information (i.e., only the most crucial part of the workflow) as possible.
                                    </p>
                                    <div class="text-center">
                                        <img src="images/forward_graph.png" alt="image" style="max-width: 60%">
                                    </div>
                                    <p>An <u>optimizer</u> works this execution graph presented by Trace. We present an initial design of an optimizer that
                                        represents this execution graph as a code debugging report, and ask an LLM to change part of the graph that is marked as 
                                        <code>trainable=True</code> according to feedback.
                                    </p>
                                    <pre>
                                        <code class="language-python">
    #Code:
    a = bar(x)
    y = add(b, a)
    z = mul(a, y)
    
    #Definitions:
    [mul] This is a multiply operator
    [add] This is an add operator.
    [bar] This is a method that does negative scaling.
    
    #Inputs: 
    b=1.0
    
    #Others:
    a=2.0    
    y=3.0
    
    #Output
    z=6.0
    
    #Variable
    x=-1.0
    
    #Feedback:
    Output should be larger.</code>
                                    </pre>
                                    <p>This debug report is presented to an LLM-based optimizer and LLM optimizer proposes changes to the variables.
                                       Note that this report may look like the actual program, but is not the same as the python program. 
                                       Even though any user can directly present the <b>FULL</b> python program to an LLM and ask it to change, it would be
                                       (1) Difficult to control LLM to only change the relevant/necessary part; (2) Hard to flexibly specify which part of the workflow LLMs should focus on.
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!-- End of Tab Content -->
                </div>
            </div>
        </div>
    </section>

    <section class="section section-lg pt-7 line-bottom-light">
        <div class="container">
            <div class="row justify-content-center mb-5 mb-lg-5">
                <div class="col-12 col-md-8 text-center">
                    <h1 class="display-3 mb-3">The Optimization Path of A Self-Adapting Battleship Agent</h1>
                    <p><img src="images/battleship_gameboard.png" style="width:30%"></p>
                    <p>We iteratively train this AI agent to play the game through a simple for loop (Fig 1 b). In each iteration, the agent (i.e. policy) sees the board configuration and tries to shoot at a target location. The environment returns in text whether it’s a hit or a miss. Then we run Trace to propagate this environment feedback through agent’s decision logic end-to-end to update the parameters (i.e. the policy is like a two-layer network with a reason layer and an act layer). These iterations mimic how a human programmer might approach the problem. They run the policy and change the code based on the observed feedback, try different heuristics to solve this problem, and they may rewrite the code a few times to fix any execution errors by using stack traces. </p>
                    <p>The presented logs are from a specific trial but are representative of the type of optimization process in the experiment.
                        In the middle circle, we show the test success rate of the agent.
                        The optimal agent does not achieve 100% success rate because of environment stochasticity.
                        <!-- <code>__code1</code> refers to the <code>act</code> method and <code>_code2</code> refers to the <code>reason</code> method. -->
                    </p>
                    <!-- <p>To start, consider building an AI agent for the classic Battleship game. In Battleship, a player’s goal to hit the ships on a hidden board as fast as possible. To this end, the player must devise strategies to cleverly locate the ships and attack them, instead of slowly enumerating the board.  </p> -->
                </div>
            </div>
            <div class="row">
                <div class="timeline timeline-six px-3 px-lg-0">
                    <!-- Timeline Item 1 -->
                    <div class="row no-gutters">
                        <div class="col-lg py-6">
                            <!--spacer-->
                            <div class="card left-timeline-card bg-soft shadow-soft border-light p-3">
                                <div class="card-body p-4">
                                    <h5 class="mb-3">Iteration 1: LLM Reasoning Log</h5>
                                    <p>The provided feedback 'Got 0 reward' likely suggests that the selected target coordinate (0, 0) from the eval1 output did not meet the criteria for gaining a reward in the game context. Both execution evaluations (__code2 and __code1) correctly run functions that are supposed to inspect a game map to find and act upon evolving game conditions. However, the problem seems to be with the plan coordination of the action based on prior analysis. Based on the current code in __code1, the function act aims to select a target if it is marked as unknown ('.') at the given coordinate and falls within the map bounds. In this instance, the target (0, 0) ends up being chosen again by eval1 even though it was processed by eval0. This recursive choice could be mitigated by further analyzing the map or considering game states that evolve. The potential issue arises from the 'plan' not being updated or handled to avoid redundancy of choices, especially after being processed once already. Hence, a modification in __code1 to verify if a coordinate is actually optimal or if alternative strategies (like prioritizing coordinates that have not been previously evaluated) would likely enhance the output.</p>
                                </div>
                            </div>
                        </div>
                        <!-- timeline item 1 center image & middle line -->
                        <div class="col-lg-1 text-center flex-column d-none d-lg-flex">
                            <div class="row h-50">
                                <div class="col">&nbsp;</div>
                                <div class="col">&nbsp;</div>
                            </div>
                            <span class="d-none d-lg-block m-4 h4 lh-200 dot-separator bg-soft shadow-soft border border-light text-primary">0%</span>
                            <div class="row h-50">
                                <div class="col middle-line">&nbsp;</div>
                                <div class="col">&nbsp;</div>
                            </div>
                        </div>
                        <!-- timeline profile card -->
                        <div class="col-lg">
                            <div class="card timeline-card bg-soft shadow-soft border-light p-3">
                                <div class="card-body p-4">
                                    <h5 class="mb-3">Iteration 1: Agent</h5>
                                    <p>Note: the comments in <code>#</code> are auto-generated by LLM, not by users.</p>
                                    <p class="my-2">
                                        <pre><code class="language-python wrap-code">class Agent:

    @bundle(trainable=True)
    def act(self, map, plan):
        """
        Given a map, select a target coordinate in a game. On map, O denotes misses, X denotes successes, and . denotes unknown positions.
        """
        # Example implementation, more sophisticated logic may be required based on intended gameplay mechanics
        return [0, 1]

    @bundle(trainable=True)
    def reason(self, map):
        """
        Given a map, analyze the board in a game. On map, O denotes misses, X denotes successes, and . denotes unknown positions.
        """
        # Check for first unknown position to try as a potential move
        for row_index, row in enumerate(map):
            for col_index, val in enumerate(row):
                if val == '.':
                    return [row_index, col_index]
        # Default to [0, 0] if no unknown positions found
        return [0, 0]</code>
                                        </pre>
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!-- Timeline Item 2 -->
                    <div class="row no-gutters">
                        <!-- timeline profile card -->
                        <div class="col-lg py-9">
                            <div class="card left-timeline-card bg-soft shadow-soft border-light p-3">
                                <div class="card-body p-4">
                                    <h5 class="mb-3">Iteration 2: LLM Reasoning Log</h5>
                                    <p>The main task here involves the decision process of selecting targets on a game map based on hits and misses ('X' for hits, 'O' for misses, and '.' for unknown positions). The two Python functions involved (__code1 and __code2) are strategies for decision-making. Function __code2 (assigned to __code2) aims to find the most optimal strategic unknown spot near hits in order to maximize the potential reward. Here, eval0 is computed based on __code2 and it results in coordinate (0, 3). However, the plan (0, 3) decided by __code2 is supposed to be utilized by __code1 in order to further evaluate and possibly adjust the decision. The problem is that the function __code1 while deciding on the game action, may or may not alter the proposed target given (plan from eval0), resulting in eval1 = (0, 1), which we know garnered a 0 reward. This suggests that the 'plan' passed to __code1 needs to more intelligently handle existing proposed targets or that the targets calculated by __code1 might not be the most strategic. Given that there is no information available to adjust the policies (Policy20 and Policy21) or the maps (list0 and list1), the primary option left is to modify __code1 to potentially include a better heuristic or logic to ensure that the suggested target is more likely to improve the game result by possibly considering proximity to 'X' similar to __code of eval0, which tries to find spots near 'X' for maximum potential reward.</p>                                </div>
                            </div>
                        </div>
                        <!-- timeline item 2 center image & middle line -->
                        <div class="col-lg-1 text-center flex-column d-none d-lg-flex">
                            <div class="row h-50">
                                <div class="col middle-line">&nbsp;</div>
                                <div class="col">&nbsp;</div>
                            </div>
                            <span class="m-4 h4 lh-200 dot-separator bg-soft shadow-soft border border-light text-primary">21%</span>                                
                            <div class="row h-50">
                                <div class="col middle-line">&nbsp;</div>
                                <div class="col">&nbsp;</div>
                            </div>
                        </div>
                        <div class="col-lg py-3">
                            <!--spacer-->
                            <div class="card timeline-card bg-soft shadow-soft border-light p-3">
                                <div class="card-body p-4">
                                    <h5 class="mb-3">Iteration 2: Agent</h5>
                                    <pre><code class="language-python">class Agent:

@bundle(trainable=True)
def act(self, map, plan):
    """
    Given a map, select a target coordinate in a game. On map, O denotes misses, X denotes successes, and . denotes unknown positions.
    """
    # Use information from plan, which is output from __code2, checking strategic position, not just first available
    best_score = -1
    best_move = [0, 0, 0]  # initially no move is considered
    for row_index, row in enumerate(map):
        for col_index, val in enumerate(row):
            if val == '.':  # consider all unknown spots
                hopes_surrounding = 0  # will hold number of '.'s around the spot
                for di in [-1, 0, 1]:
                    for dj in [-1, 0, 1]:
                        ni, nj = row_index + di, col_index + dj
                        if 0 <= ni < len(map) and 0 <= nj < len(map[0]):
                            if map[ni][nj] == '.':
                                hopes_surrounding += 1
                score = hopes_surrounding  # more '.' around, higher the chance of hit
                if score > best_score:
                    best_score = score
                    best_move = [row_index, col_index]
    if map[plan[0]][plan[1]] == '.' and best_score == -1:
        return plan  # if no better move found, and original place is still unknown
    return best_move if best_score > -1 else plan  # return the best move found, or stick with the plan if still valid

@bundle(trainable=True)
def reason(self, map):
    """
    Given a map, analyze the board in a game. On map, O denotes misses, X denotes successes, and . denotes unknown positions.
    """
    # Improved strategic approach by checking . surrounded by more . which might indicate undetected area
    max_surrounding = -1
    best_spot = [0, 0]
    for row_index, row in enumerate(map):
        for col_index, val in enumerate(row):
            if val == '.':
                surrounding = 0
                for di in [-1, 0, 1]:
                    for dj in [-1, 0, 1]:
                        ni, nj = row_index + di, col_index + dj
                        if 0 <= ni < len(map) and 0 <= nj < len(map[0]) and map[ni][nj] == '.':
                            surrounding += 1
                if surrounding > max_surrounding:
                    max_surrounding = surrounding
                    best_spot = [row_index, col_index]
    return best_spot</code>
                                    </pre>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!-- Timeline Item 3 -->
                    <div class="row no-gutters">
                        <div class="col-lg py-9">
                            <!--spacer-->
                            <div class="card left-timeline-card bg-soft shadow-soft border-light p-3">
                                <div class="card-body p-4">
                                    <h5 class="mb-3">Iteration 8: LLM Reasoning Log</h5>
                                    <p>The main task here involves the decision process of selecting targets on a game map based on hits and misses ('X' for hits, 'O' for misses, and '.' for unknown positions). The two Python functions involved (__code1 and __code2) are strategies for decision-making. Function __code2 (assigned to __code2) aims to find the most optimal strategic unknown spot near hits in order to maximize the potential reward. Here, eval0 is computed based on __code2 and it results in coordinate (0, 3). However, the plan (0, 3) decided by __code2 is supposed to be utilized by __code1 in order to further evaluate and possibly adjust the decision. The problem is that the function __code1 while deciding on the game action, may or may not alter the proposed target given (plan from eval0), resulting in eval1 = (0, 1), which we know garnered a 0 reward. This suggests that the 'plan' passed to __code1 needs to more intelligently handle existing proposed targets or that the targets calculated by __code1 might not be the most strategic.</p>
                                    <p>Given that there is no information available to adjust the policies (Policy20 and Policy21) or the maps (list0 and list1), the primary option left is to modify __code1 to potentially include a better heuristic or logic to ensure that the suggested target is more likely to improve the game result by possibly considering proximity to 'X' similar to __code of eval0, which tries to find spots near 'X' for maximum potential reward.
                                    </p>
                                </div>
                            </div>
                        </div>
                        <!-- timeline item 3 center image & middle line -->
                        <div class="col-lg-1 text-center flex-column d-none d-lg-flex">
                            <div class="row h-50">
                                <div class="col middle-line">&nbsp;</div>
                                <div class="col">&nbsp;</div>
                            </div>
                            <span class="m-4 h4 lh-200 dot-separator bg-soft shadow-soft border border-light text-primary">60%</span>
                            <div class="row h-50">
                                <div class="col middle-line">&nbsp;</div>
                                <div class="col">&nbsp;</div>
                            </div>
                        </div>
                        <!-- timeline profile card -->
                        <div class="col-lg py-2">
                            <div class="card timeline-card bg-soft shadow-soft border-light p-3">
                                <div class="card-body p-4">
                                    <h5 class="mb-3">Iteration 8: Agent</h5>
                                    <pre><code class="language-python">class Agent:

@bundle(trainable=True)
def act(self, map, plan):
    """
    Given a map, select a target coordinate in a game. On map, O denotes misses, X denotes successes, and . denotes unknown positions.
    """
    best_score = -1
    best_move = [0, 0]
    for row_index, row in enumerate(map):
        for col_index, val in enumerate(row):
            if val == '.' and [row_index, col_index] != plan:
                hopes_surrounding = 0
                for di in [-1, 0, 1]:
                    for dj in [-1, 0, 1]:
                        ni, nj = row_index + di, col_index + dj
                        if 0 <= ni < len(map) and 0 <= nj < len(map[0]):
                            if map[ni][nj] == '.':
                                hopes_surrounding += 1  # favoring positions with more unknowns surrounding
                            elif map[ni][nj] == 'X':
                                hopes_surrounding += 2  # increased incentive for moves near successful spots
                score = hopes_surrounding
                if score > best_score:
                    best_score = score
                    best_move = [row_index, col_index]
    if best_score > -1:
        return best_move
    return plan

@bundle(trainable=True)
def reason(self, map):
    """
    Given a map, analyze the board in a game. On map, O denotes misses, X denotes successes, and . denotes unknown positions.
    """
    max_surrounding = -1
    best_spot = [0, 0]
    for row_index, row in enumerate(map):
        for col_index, val in enumerate(row):
            if val == '.':
                surrounding = 0
                for di in [-1, 0, 1]:
                    for dj in [-1, 0, 1]:
                        ni, nj = row_index + di, col_index + dj
                        if 0 <= ni < len(map) and 0 <= nj < len(map[0]):
                            if map[ni][nj] == '.':
                                surrounding += 1
                            elif map[ni][nj] == 'X':
                                surrounding += 1.5  # increasing emphasis on proximity to successful hits
                if surrounding > max_surrounding:
                    max_surrounding = surrounding
                    best_spot = [row_index, col_index]
    return best_spot</code>
                                    </pre>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section section-lg pt-7 pt-lg-11 bg-primary">
        <div class="pattern top"></div>
        <div class="container">
            <div class="row justify-content-center align-items-center mb-5 mb-xl-6">
                <div class="col-12 col-md-12 text-center">
                    <div class="text-white">
                        <h2 class="h1 mb-4">Showcases</h2>
                        <p>We can extend the same idea of end-to-end optimization to train more complicated AI systems. Empirical studies showcase Trace's ability to optimize diverse problems, from numerical optimization, LLM agents, to robot control, often outperforming specialized optimizers. </p>
                    </div>
                    <div class="row">
                        <div class="col-12">
                            <!-- Tab Nav -->
                            <div class="nav-wrapper position-relative mb-2">
                                <ul class="nav nav-pills nav-fill flex-column flex-md-row" id="tabs-icons-text" role="tablist">
                                    <li class="nav-item">
                                        <a class="nav-link mb-sm-3 mb-md-0 active" id="tabs-icons-text-1-tab" data-toggle="tab" href="#tabs-icons-text-110" role="tab" aria-controls="tabs-icons-text-110" aria-selected="true"><i class="fas fa-palette mr-2"></i>Num Optimization</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link mb-sm-3 mb-md-0" id="tabs-icons-text-1-tab" data-toggle="tab" href="#tabs-icons-text-111" role="tab" aria-controls="tabs-icons-text-111" aria-selected="true"><i class="fas fa-palette mr-2"></i>Traffic Control</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link mb-sm-3 mb-md-0" id="tabs-icons-text-1-tab" data-toggle="tab" href="#tabs-icons-text-112" role="tab" aria-controls="tabs-icons-text-112" aria-selected="true"><i class="fas fa-palette mr-2"></i>Big-Bench Hard</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link mb-sm-3 mb-md-0" id="tabs-icons-text-2-tab" data-toggle="tab" href="#tabs-icons-text-113" role="tab" aria-controls="tabs-icons-text-113" aria-selected="false"><i class="fas fa-laptop-code mr-2"></i>MetaWorld</a>
                                    </li>
                                </ul>
                            </div>
                            <!-- End of Tab Nav -->
                            <!-- Tab Content -->
                            <div class="card">
                                <div class="card-body p-0">
                                    <div class="tab-content" id="tabcontent2">
                                        <div class="tab-pane fade show active" id="tabs-icons-text-110" role="tabpanel" aria-labelledby="tabs-icons-text-110-tab">
                                            <p>Exercitation photo booth stumptown tote bag Banksy, elit small batch freegan sed. Craft beer elit seitan exercitation, photo booth et 8-bit kale chips proident chillwave deep v laborum. Aliquip veniam delectus,
                                                Marfa eiusmod Pinterest in do umami readymade swag.</p>
                                            <p>Day handsome addition horrible sensible goodness two contempt. Evening for married his account removal. Estimable me disposing of be moonlight cordially curiosity.</p>
                                        </div>
                                        <div class="tab-pane fade show active" id="tabs-icons-text-111" role="tabpanel" aria-labelledby="tabs-icons-text-111-tab">
                                            <p>Exercitation photo booth stumptown tote bag Banksy, elit small batch freegan sed. Craft beer elit seitan exercitation, photo booth et 8-bit kale chips proident chillwave deep v laborum. Aliquip veniam delectus,
                                                Marfa eiusmod Pinterest in do umami readymade swag.</p>
                                            <p>Day handsome addition horrible sensible goodness two contempt. Evening for married his account removal. Estimable me disposing of be moonlight cordially curiosity.</p>
                                        </div>
                                        <div class="tab-pane fade" id="tabs-icons-text-112" role="tabpanel" aria-labelledby="tabs-icons-text-112-tab">
                                            <p>Photo booth stumptown tote bag Banksy, elit small batch freegan sed. Craft beer elit seitan exercitation, photo booth et 8-bit kale chips proident chillwave deep v laborum. Aliquip veniam delectus, Marfa eiusmod
                                                Pinterest in do umami readymade swag.</p>
                                            <p>Day handsome addition horrible sensible goodness two contempt. Evening for married his account removal. Estimable me disposing of be moonlight cordially curiosity.</p>
                                        </div>
                                        <div class="tab-pane fade" id="tabs-icons-text-113" role="tabpanel" aria-labelledby="tabs-icons-text-113-tab">
                                            <p>Photo booth stumptown tote bag Banksy, elit small batch freegan sed. Craft beer elit seitan exercitation, photo booth et 8-bit kale chips proident chillwave deep v laborum. Aliquip veniam delectus, Marfa eiusmod
                                                Pinterest in do umami readymade swag.</p>
                                            <p>Day handsome addition horrible sensible goodness two contempt. Evening for married his account removal. Estimable me disposing of be moonlight cordially curiosity.</p>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            <!-- End of Tab Content -->
                        </div>
                    </div>

                </div>
            </div>
        </div>
    </section>
    
    <section class="section pt-7 pt-lg-7">
        <!-- mt-n8 mt-lg-n12 -->
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-12 col-lg-8 text-center">
                    <h3 class="display-2 mb-3">Team</h3>
                    <p class="lead">Trace includes contributions from the following people listed alphabetically. We are also thankful to the many people
                        behind the scenes who provided support and feedback in the form of suggestions, Github issues, and reviews.</p>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="row mt-6">
                <div class="col-md-6 col-lg-4">
                    <!-- Profile Card -->
                    <div class="profile-card mb-7">
                        <div class="card shadow-soft border-light text-center">
                            <div class="profile-image">
                                <a href="https://www.chinganc.com/">
                                <img src="images/ching-an-2.jpg" class="card-img-top " alt="image">
                                </a>
                            </div>
                            <div class="card-body mt-n5">
                                <h5 class="card-title">Ching-An Cheng</h5>
                                <p class="card-subtitle">Senior Research Scientist<br>Microsoft Research</p>
                            </div>
                        </div>
                    </div>
                    <!-- End of Profile Card -->
                </div>
                <div class="col-md-6 col-lg-4">
                    <!-- Profile Card -->
                    <div class="profile-card mb-7">
                        <div class="card shadow-soft border-light text-center">
                            <div class="profile-image">
                                <a href="https://anie.me/about">
                                    <img src="images/allen-cropped.jpeg" class="card-img-top " alt="image">
                                    </a>
                            </div>
                            <div class="card-body mt-n5">
                                <h5 class="card-title">Allen Nie</h5>
                                <p class="card-subtitle">PhD<br>Stanford University</p>
                            </div>
                        </div>
                    </div>
                    <!-- End of Profile Card -->
                </div>
                <div class="col-md-6 col-lg-4">
                    <!-- Profile Card -->
                    <div class="profile-card mb-7">
                        <div class="card shadow-soft border-light text-center">
                            <div class="profile-image">
                                <a href="https://www.microsoft.com/en-us/research/people/adswamin/">
                                    <img src="images/adith.jpg" class="card-img-top " alt="image">
                                </a>
                            </div>
                            <div class="card-body mt-n5">
                                <h5 class="card-title">Adith Swaminathan</h5>
                                <p class="card-subtitle">Principle Research Scientist<br>Microsoft Research</p>
                            </div>
                        </div>
                    </div>
                    <!-- End of Profile Card -->
                </div>
            </div>
        </div>
    </section>


  <footer class="footer section pt-6 pt-md-6 pt-lg-6 pb-3 bg-primary text-white overflow-hidden">
  <!-- <div class="pattern top pattern-soft"></div> -->
  <div class="container">
     <div class="row">
      </div>
      <div class="row">
          <div class="col pb-4 mb-md-0">
              <div class="d-flex text-center justify-content-center align-items-center">
                  <p class="font-weight-normal font-small mb-0">By Ching-An Cheng, Allen Nie, Adith Swaminathan. © Copyright <span class="current-year">2024</span>. </p>
              </div>
          </div>
      </div>
  </div>
</footer>

  </main>

  <!-- Core -->
<script src="vendor/jquery/dist/jquery.min.js"></script>
<script src="vendor/popper.js/dist/umd/popper.min.js"></script>
<script src="vendor/bootstrap/dist/js/bootstrap.min.js"></script>
<script src="vendor/headroom.js/dist/headroom.min.js"></script>

<!-- Vendor JS -->
<script src="vendor/countup.js/dist/countUp.min.js"></script>
<script src="vendor/jquery-countdown/dist/jquery.countdown.min.js"></script>
<script src="vendor/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
<script src="vendor/prismjs/prism.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.17.1/components/prism-python.min.js"></script>

<!-- Chartist -->
<script src="vendor/chartist/dist/chartist.min.js"></script>
<script src="vendor/chartist-plugin-tooltips/dist/chartist-plugin-tooltip.min.js"></script>

<!-- Vector Maps -->
<script src="vendor/jqvmap/dist/jquery.vmap.min.js"></script>
<script src="vendor/jqvmap/dist/maps/jquery.vmap.world.js"></script>

<!-- Rocket JS -->
<script src="assets/js/rocket.js"></script>


</body></html>